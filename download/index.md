# Как архивировать?

## Выгрузка сайта

Самый простой способ скачать сайт программой wget, которая присутсвует почти
в любом дистрибутиве Linux:

```sh
wget --mirror -p --convert-links -P . xyz.com
```

Объяснение:

1. `--mirror` - скачать сайт целиком
2. `-p` - загрузить все файлы, необходимые для корректного отображения страницы
3. `--convert-links` - заменить ссылки на странице для возможности локальной навигации
3. `-P .` - путь сохранения, в данном случае в текущую директорию (`./xyz.com`)

## Скачивание по набору url

Последняя часть (имя файла) в ссылках должна быть уникальна, иначе последующие файлы перезапишут предыдущие.

1. Сохранить все url в файл (каждая ссылка с новой строки).

2. Перейти в директорию, в которую всё будет скачиваться. Выполнить команду:
```sh
wget -i файл_с_url
```